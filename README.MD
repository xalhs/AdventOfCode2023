# Advent of Code 2023
These are my scripts for the puzzles at https://adventofcode.com/2023 I will be uploading all days that I solve with a short commentary on thought process/description. All the puzzles (so far) have been solved without looking up any hint related to the event. Note that my naming process for the input texts is input + the date. So for the first day it was input1.txt, the second day input2.txt... etc.

## Day 1
There is not much to say about part 1, you just iterate through each line forward or backwards and pick the first number you see then concatentate them and sum all those for each line. For part 2, it's a bit trickier since there are numbers spelled out. A first idea is to replace the spelling of the number with the number itself (for example replace "two" with "2") which could work but there are issues. The main issue is when two spelled out numbers share a letter (like "eightwo") here if you replace the "eight" it will be "8wo" but then you lost the "two". The safest way to do it is to replace each spelled out number with the number but also the first and last letter of the spelled out number. For example "one" is replaced by "o1e", "two" by "t2o", "three" by "t3e"... etc. No spelled out number combinations share more than one letter so this is enough.

## Day 2
Day 2 was the first day I did of the advent of code (shoutout to Alex for showing it to me). It was fairly easy on part 1 we just needed to implement a condition on each game and see which games fulfill that. On part 2 instead of a condition we just need to see the minimum amounts of each color of cubes that are needed for each game to be possible. Then multiply them together and adding those numbers for each game.

## Day 3
Day 3 was my second day of advent of code and it was a very interesting one. For part 1, we have to find the numbers in the input that are adjacent to a symbol. To do this I iterated over the input until I found a symbol then "looked" in all 8 directions for numbers (being careful to include the whole number) and then I erased the number to not double count it. Part 2 was also interesting as it was asking us to find the "*" symbols that are adjacent to exactly 2 numbers. My solution, even though it gives the correct answer, does not take into account an edge case. It does not take into account the case where a single number borders two different "*" symbols. However, judging from my input the inputs might be hard coded as to avoid this. Regardless I could have made the code resistant to that edge case possibly with a bit more time. The code itself is basically the same as part 1 but only accounting for the "*" sumbols and only those that have two numbers adjacent. 

## Day 4
Part 1 is just comparing lists and finding matches. For each match you multiply the value of the card by 2 (or set it to 1 if it was 0), then you add all the values of the cards. Part 2 is much more confusing now instead of increasing the value of the cards, matches increase the number of future cards you get. The way I solved it was by using a list of the multiplicities of each card that I had and increased that number according to the instructions. So if card 6 had multiplicity 5 (i.e. I had 5 total copies of card 6) and card 6 had 7 matches then I added 5 to the multiplicity of cards 7 8 9 10 11 12 13.

## Day 5 
Day 5 was one of my favorites and one of the most difficult. Part 1 was a bit of a hurdle writing all the mappings. The key is figuring out that each mapping (for the range that it operates on) is just adding the difference of the beginning of the image (where it takes you) of the map with the beginning of the domain (where it came from). Part 2 was much more difficult, in principle it was the same logic as part one, however, the number of seeds now was huge since instead of individual seeds they were now ranges of seeds.  Computing them 1 by 1 was not an option. The way I solved it was that instead of operating with the maps on the seeds individually, I operated on the ranges. So I proccessed each range through the maps, splitting it accordingly at the map borders and it turned out pretty nice. Code was pretty tedious to write but it runs almost insantly so I am very happy with the result.

## Day 6
I had been wanting to do an exercise in some form other than python so day 6 seemed to be the perfect specimen. Indeed day 6 is simple algebra if done right. All we have to notice is that the distance traveled with respect to time has a symmetry along an axis. That is the distance is $x = t\cdot(T-t)$ where $x$ is the distance, $t$ is the time the boat was held down and $T$ is the total time of the race. Now we just need to find for which values of $t$, the distance is greater than the required distance. The way I did part 1 was to plot the respective equation for each input and find the integer values of $t$ ($x$ in Desmos) such that the polynomial is greater than 0. Then multiply the number of such values for each race to get the answer. Part 2 could be done the same way but we could also further notice that "essentially" the exercise asks us to find the difference between the two roots of the polynomial. Knowing the formula for the roots is $\frac{-b \pm \sqrt(b^2 -4ac)}{2a}$ and considering that $a = -1$ in this case, then we only have to find the determinant since the difference of the two roots will be that. To find it we could simply use a calculator (or Desmos). Note that we have to input an integer into the problem and the determinand will in general not be an integer. To amend for that we just take the floor of the determinant. That should usually be the correct answer, however, there might be cases where this is off by one. If we want to calculate the answer without worrying about that then we just need to calculate both roots and take the difference of their floor(). Since I didn't solve this in python there is no code but here is a link to desmos where I did the calculations: https://www.desmos.com/calculator/fw5jj74ckb.  

## Day 7 
Day 7 was a fun little exercise. The main theme is evaluating hands in a game similar to poker. The evaluation is based primarily on type (five of a kind, four of a kind... etc.) and secondarily on the strongest card in hand (from left to right). To solve this I implemented an evaluation function. It evaluates each hand in base 13 (since there are 13 different cards). The last card in hand counts for its value times $13^0$ the second to last card counts for its value times $13^1$... up until the first card which counts for its value times $13^4$. Finally the evaluation checks the type of the hand and adds an evaluation based on the type times $13^5$. This way all different hands have a different value. Then it is just a matter of calculating the order of the hands which is done by sorting the dictionary of values and then adding the bets according to the exercise. Part 2 wasn't much harder. Here the card "J" can substitute for any other card basically. The way I did it was seeing that the most optimal hand will always be if the "J"s all substitute to the same card and then I just ran the evaluation function while substituting "J" with every card then picked the highest. And then I solved it as in part 1.

## Day 8
Day 8 was fairly straightforward. The key idea for part 1 is using a dictionary to easily move between locations then once you reach the location "ZZZ" you are done and you check the number of steps. Part 2 has a small trick into it. You basically have to do the same procedure but for multiple locations simultaneously and you only finish when all of them finish. You can't use the direct way because the number of steps is too large. To solve this you must see that all movements between locations are periodic for each initial point and you can calculate the period for each individual starting location using the algorithm from part 1. Then after finding all periods the result we need is just the least common multiple of all the periods we found.

## Day 9
Day 9 was also straightforward. The solution is pretty much presented in the example. The only important thing to notice (in order to extrapolate the data) is that in the example, the extrapolating diagram has a "Pascal triangle" type of condition (but with subtraction instead of addition). With that information we can easily do as in the example and extrapolate the next value. Part 2 was the same idea but instead of extrapolating forward we extrapolate backwards. The solution is pretty similar to part 1 though.

## Day 10
Day 10 was essentially finding the length of a loop that was made with ascii characters in the input file. The code is a bit inefficient since it checks all four directions around the starting point (and so counts the loop twice) but it is still basically instant so I didn't bother to make it better. Part 2 was a bit more interesting as we had to find the area enclosed within the loop. To do this I just counted all the tiles that were within a parallelogram that contained the loop and then checked whether each tile was inside or not. To find out if a tile is inside I had to use a bit of topology. Esentially I ran the loop in one of the two directions and assigned to each tile of the loop a value depending on if the loop ran left or right through that tile (or value 0 if the loop ran up or down). Then for each tile potentially inside I counted how many "left" and "right" tiles it encountered when going up. If the total "leftness" is 0 then the tile is not inside the loop. The only thing to be careful is that if the tile is a corner tile then its left/right value is halved.  	 

## Day 11
For part 1, I just did as instructed and expanded the universe, then I just made a list of all the positions of galaxies and used the taxicab geometry to find their pairwise relative distance. For part 2 you could in theory do the same thing as part one but with a bigger expansion coefficient, however, this is not computationally efficient (or realistically feasible) so you have to go about it in a smarter way. The way I did it was to just mark the positions of the galaxies on the unexpanded universe then check how many rows and columns are to be expanded between them and add that to their relative distance. 

## Day 14
Day 14 was interesting, the first part was pretty easy, we just have to check for each "." whether there is an "O" or a "#" somewhere below it, if it's an "O" then we swap the two. Then after doing that for all entries we just calculate the load based on the position of the "O"s. Part 2 was a bit more interesting, it involves tilting the pattern in other directions than North. To do that I simply made a function to rotate clockwise the whole pattern and then rotated North as before. The interesting part comes from the fact that we need to do a whole cycle of rotations a billion times. Clearly that is not computationally efficient so we have to find a smarter way. My guess was that after a few cycles the pattern would reach a stable position which would not change with more cycles. What actually happens is that the pattern enters a loop of positions that alternate periodically. To solve it I just ran the cycle enough times to reach this periodicity and then I calculated the period (which was 18, this was done by hand but it wouldn't be hard to add the period calculation into the algorithm). Finally I only evaluated the positions $i$ such that $i \equiv 1000000000 (\mathrm{mod} 18)$. (Since the position repeats every 18 cycles, then the pattern at $i$ would be the same as the pattern at 1 billion considering the period is 18). Then I just calculated the load for that pattern. 

## Day 15
Day 15 was pretty easy, the first part is just applying some hash algorithm. The second part was confusing to read but it's pretty clear from the description that we are supposed to use dictionaries which make the puzzle pretty easy.

## Day 16
Day 16 was a nice puzzle. It is mainly following algorithmic instructions for the "beam" and then handling the multiple beams that pop up. The way I solved it was to just follow one beam and whenever it split I continued on one path and appended the other beam to a list of beams. When the beam reched a wall or went to a space and direction another beam has already been to then I'd remove it from the list. When the list is empty then all the beams would have been accounted for and then we can just count the tiles it has been to. For part 2 we have to do the same but for all directions and initial positions (along the border) and find which one energizes the most tiles. Honestly the shape is not that large so the border is in the order of a few hundred tiles. I did the brute force way and I got the answer after a few minutes of runtime. There is probably a better way considering this part alone has a runtime greater than the combined runtime of all other days and parts but I couldn't think of it and a few minutes isn't that long. I thought whether the part where the beam hits the wall gives the same value as the beam coming from that wall but the beam path is not reversible (because of the splitters). To be honest seeing as all the energized values are either ~8000 or around ~100, the solution might be that there is a tile and direction that if the beam goes through then it picks up a huge amount of tiles (but always the same amount since it's the same beam) so whenever it hits that tile we can just add the amount and forget about doing the calculations. However, it might be too annoying to code that solution after solving the problem. If I solve everything else then I might return to this one to do it better

## Day 18
Day 18 was another interesting puzzle. Part 1 wasn't that difficult. The main point was "drawing" correctly the shape and then finding a way to tell whether a space is inside the shape or not. The way I did it was using a bit of topology (similar to day 10). The curve went clockwise so it means that when approaching the curve from the west, we will first hit a region where the curve went "upwards". As long as the "upness" is positive (and not 0) we are inside the shape. When we hit a point where the curve goes downwards then the "upness" goes back to 0 and we are outside the shape. A little care needs to be taken on corner points which in order for the algorithm to work, should count as half the "upness" of edge points. Part 2 now made the shape much much larger. Counting individually the spaces inside is no longer feasible so we have to find a more efficient way. One thing to notice though is that the shape still remains as simple as in part 1 (meaning it still has the same amount of corners), its size is just larger. We can take advantage of this and realize that the vast majority of rows will be duplicates of other rows (similarly for columns). So I used what I called "important rows" (and columns). Those are the rows and columns that contain corners (as well as the rows and columns next to these). Then we just have to evaluate what happens on those rows/columns and then everything in-between is just a repeat of what happened in the last important row/column. This method makes this very large computation almost instant.  

## Day 19
Day 19 was very interesting. Part 1 was just translating the commands of the input into commands in code. To solve it I used a nested function which terminated when the configuration was accepted or rejected. Part 2 is where it gets interesting. Here we had to figure out the configuration space of the parameters that are accepted. To do this I used a similar function to part 1 but instead of a single configuration it uses ranges of configurations as input. When it hits an instruction (such as an inequality), the range splits and the function is called again with the new range. If finally some range gets accepted then the size of the configuration space is added to the sum.